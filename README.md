

# Demo Video:

In each video, the red rectangle represents the actual user view, and the yellow rectangle represents the viewport predicted by the Velocity method for comparison. For the LiveObj method, the blue rectangle represents the detected objects, the green tiles represent the predicted viewport, and the purple tiles represent the ones that are not selected into the predicted viewport.

# Source code:

Under this folder, there are two files "LiveObj.py" and "darknet.py". To evaluate our algorithm, please run "LiveObj.py". Before you run the code:

- Please download the latest pre-trained model from the [link](https://pjreddie.com/darknet/yolo/). 

- Please download the dataset following the paper "A Dataset for Exploring User Behaviors in VR Spherical Video Streaming."

